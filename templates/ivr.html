{% extends "base.html" %}

{% block title %}Conversational IVR - Voice Assistant{% endblock %}

{% block content %}
<div style="max-width: 800px; margin: 0 auto;">
    <h1 style="color: #0d1846; text-align: center; margin-bottom: 30px;">Conversational IVR System</h1>

    <div id="status"
        style="text-align: center; margin-bottom: 20px; padding: 10px; background-color: #f0f0f0; border-radius: 5px;">
        Click "Start Recording" to begin
    </div>

    <div style="text-align: center; margin-bottom: 30px;">
        <button id="startBtn"
            style="background-color: #28a745; font-size: 16px; padding: 12px 24px; border-radius: 5px;">
            üé§ Start Recording
        </button>
        <button id="stopBtn"
            style="background-color: #dc3545; font-size: 16px; padding: 12px 24px; border-radius: 5px; display: none;">
            ‚èπÔ∏è Stop Recording
        </button>
        <button id="clearBtn"
            style="background-color: #6c757d; font-size: 16px; padding: 12px 24px; border-radius: 5px;">
            üóëÔ∏è Clear
        </button>
    </div>

    <div style="margin-bottom: 20px;">
        <h3 style="color: #0d1846;">Conversation:</h3>
        <div id="conversation"
            style="background-color: #f8f9fa; padding: 15px; border-radius: 5px; max-height: 400px; overflow-y: auto;">
            <p style="color: #666;">Conversation will appear here...</p>
        </div>
    </div>

    <div style="margin-bottom: 20px;">
        <h3 style="color: #0d1846;">Live Transcript (demo streaming):</h3>
        <div id="liveTranscript"
            style="background-color: #eef7ff; padding: 15px; border-radius: 5px; min-height: 60px;"></div>
    </div>

    <div style="margin-bottom: 20px;">
        <h3 style="color: #0d1846;">Intent Analysis:</h3>
        <div id="intentDisplay" style="background-color: #e7f3ff; padding: 15px; border-radius: 5px;">
            <p style="color: #666; margin: 0;">Intent information will appear here...</p>
        </div>
    </div>
</div>

<audio id="responseAudio" style="display: none;"></audio>

<script>
    let mediaRecorder;
    let audioChunks = [];
    let sessionId = 'session_' + Math.random().toString(36).substring(7);

    const startBtn = document.getElementById('startBtn');
    const stopBtn = document.getElementById('stopBtn');
    const clearBtn = document.getElementById('clearBtn');
    const status = document.getElementById('status');
    const conversation = document.getElementById('conversation');
    const intentDisplay = document.getElementById('intentDisplay');
    const responseAudio = document.getElementById('responseAudio');

    startBtn.addEventListener('click', startRecording);
    stopBtn.addEventListener('click', stopRecording);
    clearBtn.addEventListener('click', clearConversation);

    async function startRecording() {
        try {
            const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
            mediaRecorder = new MediaRecorder(stream);
            audioChunks = [];

            mediaRecorder.ondataavailable = (event) => {
                audioChunks.push(event.data);
            };

            mediaRecorder.onstop = async () => {
                const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
                await processRecording(audioBlob);
            };

            // Start server-side streaming session
            try {
                await fetch('/api/stream/start', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({ session_id: sessionId })
                });
            } catch (e) { /* non-fatal */ }

            // Send small chunks periodically to mimic live streaming
            const CHUNK_MS = 1500; // 1.5s chunks
            mediaRecorder.start(CHUNK_MS);

            mediaRecorder.ondataavailable = async (event) => {
                if (event.data && event.data.size > 0 && mediaRecorder.state !== 'inactive') {
                    try {
                        const wavBlob = await webmToWav(event.data);
                        const formData = new FormData();
                        formData.append('audio', wavBlob, 'chunk.wav');
                        formData.append('session_id', sessionId);
                        const r = await fetch('/api/stream/chunk', { method: 'POST', body: formData });
                        const j = await r.json();
                        if (j.success) {
                            document.getElementById('liveTranscript').textContent = j.transcript || '';
                        }
                    } catch (err) {
                        // ignore individual chunk errors
                    }
                }
            };
            status.textContent = 'üî¥ Recording... Speak now';
            startBtn.style.display = 'none';
            stopBtn.style.display = 'inline-block';

        } catch (error) {
            console.error('Error accessing microphone:', error);
            status.textContent = '‚ùå Error accessing microphone. Please check permissions.';
            startBtn.style.display = 'inline-block';
            stopBtn.style.display = 'none';
        }
    }

    function stopRecording() {
        if (mediaRecorder && mediaRecorder.state !== 'inactive') {
            mediaRecorder.stop();
            mediaRecorder.stream.getTracks().forEach(track => track.stop());
            status.textContent = '‚è≥ Processing...';
            startBtn.style.display = 'inline-block';
            stopBtn.style.display = 'none';
        }
    }

    async function webmToWav(webmBlob) {
        // Convert WebM to WAV using Web Audio API
        const arrayBuffer = await webmBlob.arrayBuffer();
        const audioContext = new AudioContext();
        const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);

        // Get the PCM data
        const pcmData = audioBuffer.getChannelData(0);

        // Create WAV file
        const wavBuffer = new ArrayBuffer(44 + pcmData.length * 2);
        const view = new DataView(wavBuffer);

        // Write WAV header
        const writeString = (offset, string) => {
            for (let i = 0; i < string.length; i++) {
                view.setUint8(offset + i, string.charCodeAt(i));
            }
        };

        writeString(0, 'RIFF');
        view.setUint32(4, 36 + pcmData.length * 2, true);
        writeString(8, 'WAVE');
        writeString(12, 'fmt ');
        view.setUint32(16, 16, true);
        view.setUint16(20, 1, true);
        view.setUint16(22, 1, true);
        view.setUint32(24, audioBuffer.sampleRate, true);
        view.setUint32(28, audioBuffer.sampleRate * 2, true);
        view.setUint16(32, 2, true);
        view.setUint16(34, 16, true);
        writeString(36, 'data');
        view.setUint32(40, pcmData.length * 2, true);

        // Convert float samples to 16-bit PCM
        let offset = 44;
        for (let i = 0; i < pcmData.length; i++) {
            const sample = Math.max(-1, Math.min(1, pcmData[i]));
            view.setInt16(offset, sample < 0 ? sample * 0x8000 : sample * 0x7FFF, true);
            offset += 2;
        }

        return new Blob([wavBuffer], { type: 'audio/wav' });
    }

    async function processRecording(audioBlob) {
        // Convert WebM to WAV
        status.textContent = '‚è≥ Converting audio...';

        let wavBlob;
        try {
            wavBlob = await webmToWav(audioBlob);
        } catch (error) {
            console.error('Error converting to WAV:', error);
            status.textContent = '‚ö†Ô∏è Using original format...';
            wavBlob = audioBlob;
        }

        // Use accumulated transcript from streaming only (no single-shot fallback)
        status.textContent = '‚è≥ Getting transcript...';

        let userMessage = '';
        try {
            const s = await fetch(`/api/stream/stop`, {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify({ session_id: sessionId })
            });
            const sj = await s.json();
            if (sj && sj.success && sj.transcript) {
                userMessage = sj.transcript;
            }
        } catch (e) { /* ignore */ }

        try {
            if (!userMessage) throw new Error('No transcript available from streaming');
            if (!userMessage) throw new Error('No transcript available');
            addToConversation('user', userMessage);
            status.textContent = '‚è≥ Analyzing intent and generating response...';

            // Get conversational response
            const converseResponse = await fetch('/api/converse', {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json'
                },
                body: JSON.stringify({
                    message: userMessage,
                    session_id: sessionId
                })
            });

            const converseData = await converseResponse.json();

            if (converseData.success) {
                addToConversation('assistant', converseData.response);
                displayIntent(converseData.intent, converseData.confidence, converseData.reasoning);

                // Synthesize response audio
                await synthesizeAndPlay(converseData.response);
            } else {
                addToConversation('system', 'Sorry, I encountered an error.');
            }

            status.textContent = '‚úÖ Ready';

        } catch (error) {
            console.error('Error processing recording:', error);
            status.textContent = '‚ùå Error processing recording';
            addToConversation('system', 'Error processing your message.');
        }
    }

    async function synthesizeAndPlay(text) {
        try {
            const response = await fetch('/api/synthesize', {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json'
                },
                body: JSON.stringify({
                    text: text,
                    session_id: sessionId
                })
            });

            if (response.ok) {
                const audioBlob = await response.blob();
                const audioUrl = URL.createObjectURL(audioBlob);
                responseAudio.src = audioUrl;
                responseAudio.play();
            }
        } catch (error) {
            console.error('Error synthesizing speech:', error);
        }
    }

    function addToConversation(role, message) {
        const messageDiv = document.createElement('div');
        messageDiv.style.marginBottom = '10px';
        messageDiv.style.padding = '10px';

        if (role === 'user') {
            messageDiv.style.backgroundColor = '#d1ecf1';
            messageDiv.style.textAlign = 'right';
            messageDiv.innerHTML = `<strong>You:</strong> ${message}`;
        } else if (role === 'assistant') {
            messageDiv.style.backgroundColor = '#fff3cd';
            messageDiv.innerHTML = `<strong>Assistant:</strong> ${message}`;
        } else {
            messageDiv.style.backgroundColor = '#f8d7da';
            messageDiv.innerHTML = `<strong>System:</strong> ${message}`;
        }

        conversation.appendChild(messageDiv);
        conversation.scrollTop = conversation.scrollHeight;
    }

    function displayIntent(intent, confidence, reasoning) {
        const intentColors = {
            'question': '#28a745',
            'complaint': '#dc3545',
            'other': '#6c757d'
        };

        intentDisplay.innerHTML = `
        <strong>Intent:</strong> <span style="color: ${intentColors[intent] || '#000'}; text-transform: uppercase;">${intent}</span>
        <br><strong>Confidence:</strong> ${(confidence * 100).toFixed(1)}%
        <br><strong>Reasoning:</strong> ${reasoning}
    `;
    }

    async function clearConversation() {
        conversation.innerHTML = '<p style="color: #666;">Conversation cleared.</p>';
        intentDisplay.innerHTML = '<p style="color: #666; margin: 0;">Intent information will appear here...</p>';

        await fetch('/api/clear-session', {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json'
            },
            body: JSON.stringify({
                session_id: sessionId
            })
        });

        status.textContent = 'Ready';
    }
</script>
{% endblock %}